{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd2929c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "# \n",
    "from ebrec.utils._constants import (\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL, \n",
    "    DEFAULT_CLICKED_ARTICLES_COL,\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,\n",
    "    DEFAULT_IMPRESSION_ID_COL,\n",
    "    DEFAULT_SUBTITLE_COL,\n",
    "    DEFAULT_LABELS_COL,\n",
    "    DEFAULT_TITLE_COL, \n",
    "    DEFAULT_USER_COL, \n",
    ")\n",
    "#\n",
    "from ebrec.utils._behaviors import (\n",
    "    create_binary_labels_column, \n",
    "    sampling_strategy_wu2019,\n",
    "    add_known_user_column,\n",
    "    add_prediction_scores,\n",
    "    truncate_history, \n",
    ")\n",
    "from ebrec.utils._articles import convert_text2encoding_with_transformers\n",
    "from ebrec.utils._polars import concat_str_columns, slice_join_dataframes\n",
    "from ebrec.utils._articles import create_article_id_to_value_mapping\n",
    "from ebrec.utils._nlp import get_transformers_word_embeddings\n",
    "#\n",
    "from ebrec.models.newsrec.dataloader import NRMSDataLoader\n",
    "from ebrec.models.newsrec.model_config import hparams_nrms\n",
    "from ebrec.models.newsrec import NRMSModel\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from ebrec.models.fastformer.dataloader import FastformerDataset\n",
    "from ebrec.models.fastformer.dataloader import train as train_fastformer\n",
    "from ebrec.models.fastformer.dataloader import evaluate as evaluate_fastformer\n",
    "from torch.utils.data import DataLoader\n",
    "from ebrec.models.fastformer.fastformer import Fastformer\n",
    "from ebrec.models.fastformer.config import FastFormerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be48e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"/home/data/dataset/origin/ebnerd_demo/\")\n",
    "N_SAMPLES = \"n\"\n",
    "COLUMNS = [DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL, DEFAULT_INVIEW_ARTICLES_COL, DEFAULT_CLICKED_ARTICLES_COL,N_SAMPLES]\n",
    "HISTORY_SIZE = 30\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74293038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ebnerd_from_path(path:Path, history_size:int = 30) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load ebnerd - function \n",
    "    \"\"\"\n",
    "    df_history = (\n",
    "        pl.scan_parquet(path.joinpath(\"history.parquet\"))\n",
    "        .select(DEFAULT_USER_COL, DEFAULT_HISTORY_ARTICLE_ID_COL)\n",
    "        .pipe(\n",
    "            truncate_history,\n",
    "            column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            history_size=history_size,\n",
    "            padding_value=0,\n",
    "        )\n",
    "    )\n",
    "    df_behaviors = (\n",
    "        pl.scan_parquet(path.joinpath(\"behaviors.parquet\"))\n",
    "        .with_columns(pl.col(DEFAULT_INVIEW_ARTICLES_COL).list.len().alias(N_SAMPLES))\n",
    "        .collect()\n",
    "        .pipe(\n",
    "            slice_join_dataframes, df2=df_history.collect(), on=DEFAULT_USER_COL, how=\"left\"\n",
    "        )\n",
    "    )\n",
    "    return df_behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa7235a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = (\n",
    "    ebnerd_from_path(path.joinpath(\"train\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(sampling_strategy_wu2019,npratio=4,shuffle=True,with_replacement=True, seed=123)\n",
    "    .pipe(create_binary_labels_column)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ead3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = (\n",
    "    ebnerd_from_path(path.joinpath(\"validation\"), history_size=HISTORY_SIZE)\n",
    "    .select(COLUMNS)\n",
    "    .pipe(create_binary_labels_column)\n",
    ")\n",
    "label_lengths = df_validation[DEFAULT_INVIEW_ARTICLES_COL].list.len().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93b1b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMER_MODEL_NAME = \"/home/data/models/bert-base-multilingual-cased\"\n",
    "TEXT_COLUMNS_TO_USE = [DEFAULT_SUBTITLE_COL, DEFAULT_TITLE_COL]\n",
    "MAX_TITLE_LENGTH = 30\n",
    "\n",
    "# LOAD HUGGINGFACE:\n",
    "transformer_model = AutoModel.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n",
    "# We'll init the word embeddings using the \n",
    "word2vec_embedding = get_transformers_word_embeddings(transformer_model)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21cc0870",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pl.read_parquet(path.joinpath(\"articles.parquet\"))\n",
    "df_articles, cat_cal = concat_str_columns(df_articles, columns=TEXT_COLUMNS_TO_USE)\n",
    "df_articles, token_col_title = convert_text2encoding_with_transformers(\n",
    "    df_articles, transformer_tokenizer, cat_cal, max_length=MAX_TITLE_LENGTH\n",
    ")\n",
    "article_mapping = create_article_id_to_value_mapping(df=df_articles, value_col=token_col_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67cd8133",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    FastformerDataset(\n",
    "        behaviors=df_train,\n",
    "        history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "        article_dict=article_mapping,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f86d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    FastformerDataset(\n",
    "        behaviors=df_validation,\n",
    "        history_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "        article_dict=article_mapping,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "921c5d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"FastFormer\"\n",
    "LOG_DIR = f\"/home/data/models/{MODEL_NAME}/log\"\n",
    "MODEL_WEIGHTS = f\"/home/data/models/{MODEL_NAME}/weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c1f56f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = FastFormerConfig()\n",
    "model = Fastformer(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0978bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d0d388e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]:   0%|                                      | 0/249 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_fastformer(model\u001b[38;5;241m=\u001b[39mmodel, \\\n\u001b[1;32m      2\u001b[0m                  train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader, \\\n\u001b[1;32m      3\u001b[0m                  criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \n\u001b[1;32m      4\u001b[0m                 optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m      5\u001b[0m                  scheduler\u001b[38;5;241m=\u001b[39mscheduler,\n\u001b[1;32m      6\u001b[0m                  num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs, \\\n\u001b[1;32m      7\u001b[0m                  val_dataloader\u001b[38;5;241m=\u001b[39mtest_dataloader, \\\n\u001b[1;32m      8\u001b[0m                  state_dict_path\u001b[38;5;241m=\u001b[39mMODEL_WEIGHTS, \\\n\u001b[1;32m      9\u001b[0m                  monitor_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m                 )\n",
      "File \u001b[0;32m/home/work/ebnerd-benchmark/src/ebrec/models/fastformer/dataloader.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, criterion, optimizer, scheduler, num_epochs, val_dataloader, state_dict_path, patience, summary_writer, gradient_accumulation_steps, tqdm_disable, tqdm_ncol, monitor_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m batch_input_label_concatenation(inputs, labels)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# => Forward pass\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m    182\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# => Backward pass and optimization\u001b[39;00m\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/ebnerd/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/ebnerd/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/home/work/ebnerd-benchmark/src/ebrec/models/fastformer/fastformer.py:427\u001b[0m, in \u001b[0;36mFastformer.forward\u001b[0;34m(self, history_input, candidate_input)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the forward pass of the Fastformer model.\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;124;03mProcesses the user click-history and candidate articles, and produces a relevance score.\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m    torch.float: A tensor of shape (batch_size, 1) representing the relevance scores.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# ====\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# output: (batch_size, hidden_dimension)\u001b[39;00m\n\u001b[0;32m--> 427\u001b[0m user_encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_encoder(history_input)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# ====\u001b[39;00m\n\u001b[1;32m    430\u001b[0m attention_mask_candidate_input \u001b[38;5;241m=\u001b[39m candidate_input\u001b[38;5;241m.\u001b[39mbool()\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m/home/work/ebnerd-benchmark/src/ebrec/models/fastformer/fastformer.py:397\u001b[0m, in \u001b[0;36mFastformer.user_encoder\u001b[0;34m(self, history_input)\u001b[0m\n\u001b[1;32m    395\u001b[0m slice_input \u001b[38;5;241m=\u001b[39m embds_history_input[:, i, :, :]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnews_encoder(slice_input, attention_mask_tokens)\n\u001b[0;32m--> 397\u001b[0m slice_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnews_encoder(\n\u001b[1;32m    398\u001b[0m     slice_input, attention_mask_tokens\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    399\u001b[0m )\n\u001b[1;32m    400\u001b[0m outputs\u001b[38;5;241m.\u001b[39mappend(slice_output\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# self.news_encoder_standard(slice_input, attention_mask_tokens)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/ebnerd/lib/python3.11/site-packages/torch/nn/modules/module.py:1675\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1669\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1674\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1677\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_fastformer(model=model, \\\n",
    "                 train_dataloader=train_dataloader, \\\n",
    "                 criterion=None, \n",
    "                optimizer=optimizer,\n",
    "                 scheduler=scheduler,\n",
    "                 num_epochs=num_epochs, \\\n",
    "                 val_dataloader=test_dataloader, \\\n",
    "                 state_dict_path=MODEL_WEIGHTS, \\\n",
    "                 monitor_metric=\"auc\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a2cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03e3e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb168076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ebnerd]",
   "language": "python",
   "name": "conda-env-ebnerd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
